{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059896b8-f6a9-4e26-a4cf-b2cd4b85e3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dd6e455-164c-4fbc-bfe1-71ee7e1f2192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'M2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(dgc\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m----> 3\u001b[0m     dgc \u001b[38;5;241m=\u001b[39m dgc[i]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, dgc])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'M2'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in sorted(dgc.keys()):\n",
    "    dgc = dgc[i].drop(columns=['ID'])\n",
    "    df = pd.concat([df, dgc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871ad530-09f6-46af-89d6-4b443d63e41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "heade = ['ID', 'M1', 'M2', 'S1', 'S2', 't_pair', 't_elapsed', 'Mrem', 'Srem', 'esca_v', 'Mtot', 'gen']\n",
    "\n",
    "path_data = './data/'\n",
    "dyn = '/Dyn/' # Direi che così è facilmente customizzabile per come ogni autistic* si è sistemato i files.\n",
    "\n",
    "def extractor(path_data, cluster):\n",
    "    dataset = {}\n",
    "    wichcluster = os.listdir(path_data)\n",
    "    if cluster == 'gc':\n",
    "        cluster = wichcluster[2]\n",
    "    if cluster == 'nsc':\n",
    "        cluster = wichcluster[1]\n",
    "    if cluster == 'ysc':\n",
    "        cluster = wichcluster[0]\n",
    "    for i in os.listdir(path_data + cluster + dyn):\n",
    "        name = path_data + cluster + '/Dyn/' + str(i) + '/nth_generation.txt'\n",
    "        dataset[str(i)]=pd.read_csv(name, delimiter=' ', skiprows=1, header=None)#, names=heade)\n",
    "        dataset[str(i)].drop(dataset[str(i)].columns[[5, 6, 7, 8, 10, 11, 12, 14, 18, 19, 20, 21, 22, 23, 24, 26]], axis=1, inplace=True)\n",
    "        dataset[str(i)].columns = heade\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffd6ea3d-0170-4392-a8c0-ee0fe56bc91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gc = extractor(path_data,'gc') # globular clusters\n",
    "#df_nsc = extractor(path_data,'nsc') # nuclear clusters\n",
    "#df_ysc = extractor(path_data,'ysc') # young star clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780a88d0-b2ed-44aa-a4ed-127e4e4e7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef25004-8f81-4059-a394-e19c3302c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "dfa = df_gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de6e4efc-c15f-428c-a98e-82a75ecf4c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change z. 0.0002\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.240332\n",
      "esca_v       0.160507\n",
      "M1           0.130751\n",
      "Mrem         0.125610\n",
      "S1           0.112735\n",
      "M2           0.111477\n",
      "t_pair       0.063521\n",
      "Mtot         0.039476\n",
      "S2           0.007888\n",
      "Srem         0.007705\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.0004\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.222410\n",
      "esca_v       0.155610\n",
      "Mrem         0.138090\n",
      "M1           0.131224\n",
      "M2           0.117376\n",
      "S1           0.113085\n",
      "t_pair       0.065221\n",
      "Mtot         0.036997\n",
      "Srem         0.012295\n",
      "S2           0.007692\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.0008\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.255284\n",
      "esca_v       0.157150\n",
      "M1           0.134493\n",
      "M2           0.113533\n",
      "S1           0.111971\n",
      "Mrem         0.104766\n",
      "t_pair       0.072431\n",
      "Mtot         0.034477\n",
      "Srem         0.009566\n",
      "S2           0.006328\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.0012\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.256204\n",
      "esca_v       0.159376\n",
      "M1           0.137405\n",
      "S1           0.114149\n",
      "M2           0.111833\n",
      "Mrem         0.103734\n",
      "t_pair       0.066906\n",
      "Mtot         0.037565\n",
      "Srem         0.006709\n",
      "S2           0.006120\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.0016\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.253328\n",
      "esca_v       0.155592\n",
      "M1           0.136570\n",
      "Mrem         0.112726\n",
      "S1           0.110483\n",
      "M2           0.105475\n",
      "t_pair       0.066636\n",
      "Mtot         0.037154\n",
      "Srem         0.015033\n",
      "S2           0.007003\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.002\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.257896\n",
      "esca_v       0.159798\n",
      "M1           0.142506\n",
      "Mrem         0.117102\n",
      "S1           0.107964\n",
      "M2           0.101565\n",
      "t_pair       0.067775\n",
      "Mtot         0.031936\n",
      "Srem         0.007489\n",
      "S2           0.005969\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.004\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "esca_v       0.159654\n",
      "t_elapsed    0.157013\n",
      "S1           0.153953\n",
      "Mrem         0.143794\n",
      "M1           0.132598\n",
      "M2           0.114911\n",
      "t_pair       0.065987\n",
      "Mtot         0.057758\n",
      "S2           0.008758\n",
      "Srem         0.005574\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.006\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.220894\n",
      "esca_v       0.159151\n",
      "Mrem         0.134953\n",
      "M1           0.134476\n",
      "M2           0.113912\n",
      "S1           0.105769\n",
      "t_pair       0.065392\n",
      "Mtot         0.052189\n",
      "Srem         0.007076\n",
      "S2           0.006188\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.008\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.231775\n",
      "esca_v       0.169313\n",
      "Mrem         0.136060\n",
      "M1           0.128714\n",
      "M2           0.112384\n",
      "S1           0.107445\n",
      "Mtot         0.052467\n",
      "t_pair       0.048825\n",
      "Srem         0.007056\n",
      "S2           0.005962\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.012\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.250157\n",
      "esca_v       0.158660\n",
      "Mrem         0.154583\n",
      "M1           0.139976\n",
      "S1           0.107656\n",
      "t_pair       0.072374\n",
      "M2           0.069468\n",
      "Mtot         0.029460\n",
      "Srem         0.011536\n",
      "S2           0.006131\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.016\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.280355\n",
      "esca_v       0.159725\n",
      "M1           0.144001\n",
      "Mrem         0.134155\n",
      "S1           0.112879\n",
      "t_pair       0.075368\n",
      "M2           0.051079\n",
      "Mtot         0.024073\n",
      "Srem         0.010690\n",
      "S2           0.007676\n",
      "Name: average_importance, dtype: float64\n",
      "change z. 0.02\n",
      "change feature, M1\n",
      "change feature, M2\n",
      "change feature, S1\n",
      "change feature, S2\n",
      "change feature, t_pair\n",
      "change feature, t_elapsed\n",
      "change feature, Mrem\n",
      "change feature, Srem\n",
      "change feature, esca_v\n",
      "change feature, Mtot\n",
      "change feature, gen\n",
      "t_elapsed    0.204881\n",
      "esca_v       0.152578\n",
      "S1           0.142327\n",
      "M2           0.125305\n",
      "M1           0.117388\n",
      "Mrem         0.117135\n",
      "Mtot         0.067776\n",
      "t_pair       0.060395\n",
      "Srem         0.007277\n",
      "S2           0.004938\n",
      "Name: average_importance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Store feature importance results\n",
    "feature_importances = {}\n",
    "avg_importances_ysc = {}\n",
    "\n",
    "\n",
    "for i in sorted(dfa.keys()):\n",
    "    df = dfa[str(i)].drop(columns=['ID'])\n",
    "    print(f'change z. {i}')\n",
    "    # Iterate through each feature as the target\n",
    "    for target_feature in df.columns:\n",
    "        print(f'change feature, {target_feature}')\n",
    "        # Define predictors (X) and target (y)\n",
    "        X = df.drop(columns=[target_feature])\n",
    "        y = df[target_feature]\n",
    "\n",
    "        # Split into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Train a Random Forest model\n",
    "        model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Store feature importance for the current target\n",
    "        feature_importances[target_feature] = model.feature_importances_\n",
    "\n",
    "    # Convert to a DataFrame for easier interpretation\n",
    "    importance_df = pd.DataFrame(feature_importances, index=X.columns)\n",
    "\n",
    "    # Calculate average importance across all targets\n",
    "    importance_df[\"average_importance\"] = importance_df.mean(axis=1)\n",
    "\n",
    "    # Sort features by average importance\n",
    "    sorted_importances = importance_df[\"average_importance\"].sort_values(ascending=False)\n",
    "    print(sorted_importances)\n",
    "    sorted_importances['Z-No correlation'] = i\n",
    "    \n",
    "    avg_importances_ysc[i] = sorted_importances\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dd8e6b1-d9c3-45b9-b6e3-422658018457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.DataFrame(avg_importances_ysc)\n",
    "file.to_csv('avg_imp_gc.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
